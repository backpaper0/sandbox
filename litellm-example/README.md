# LiteLLM example

```bash
docker compose up -d
```

LiteLLMã‚’çµŒç”±ã—ã¦[Anthropicã®Messages API](https://docs.anthropic.com/en/api/messages)ã§[Ollama](https://ollama.com/)ã§å‹•ã‹ã—ã¦ã„ã‚‹`gpt-oss:20b`ã¸ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡ã—ã¦ã¿ã‚‹ã€‚
å‰æã¨ã—ã¦`ollama serve`ã§Ollamaã‚’èµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã€‚

```bash
curl localhost:4000/v1/messages -s \
  --json '{"model":"gpt-oss","max_tokens":1024,"messages":[{"role":"user","content":"ã‚„ã‚"}]}' | jq
```

``json
{
  "id": "chatcmpl-5d4602d4-5860-40ef-8e1d-1259bc97b03a",
  "type": "message",
  "role": "assistant",
  "model": "ollama/gpt-oss:20b",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 73,
    "output_tokens": 135
  },
  "content": [
    {
      "type": "text",
      "text": "ã‚„ã‚ï¼ã“ã‚“ã«ã¡ã¯ ğŸ˜Š  \nä»Šæ—¥ã¯ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿã©ã‚“ãªè©±é¡Œã§ã‚‚å¤§ä¸ˆå¤«ã§ã™ã‚ˆï¼"
    }
  ],
  "stop_reason": "end_turn"
}
```

